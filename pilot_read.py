'''
This module is used for reading and preprocessing the images of the data set.
It is used by the pilot_CNN network.

Usage:
run for testing $python pilot_read.py.
'''
import os
import tensorflow as tf
from os import listdir
from os.path import isfile,join
import numpy as np
from PIL import Image
import string

#number of times data is used for training and given as input
max_num_epochs = 5
#file generated by create_image_list.py
image_label_list = 'imglist_generated_tmp.txt'
batch_size = 10
data_type = 'app' #can be app, flow or both
NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN = 150

class DataError(Exception):
    def __init__(self, value):
        self.value = value
    def __str__(self):
        return repr(self.value)


def read_my_file_format(filename_and_label_tensor, data_type='app'):
    """Consumes a single filename and label as a ' '-delimited string.
    If you want N-way read parallellism, call this function N-times.
    Args:
        filename_and_label_tensor: A scalar string tensor.
        data_type: appearance, flow or both
    Returns:
        An object representing a single data object with the following fields:
        height: number of rows in the result
        width: number of columns in the result
        depth: number of color channels in the result 3 for 1 image
        label: an int32 Tensor with the label in the range 0..3.
        rgb_image: a [height, width, depth] uint8 Tensor with the image data 
        flow_image: a [height, width, depth] uint8 Tensor with the image data
    """
    class DataRecord(object):
        pass
    result = DataRecord()
    #get filename and label from the scalar string tensor
    result.rgbfile, result.flowfile, result.label = tf.decode_csv(filename_and_label_tensor, [[""], [""], [""]], " ")
    if data_type=='both' or data_type=='app':
        #read_file to get a string representation of the image in filename
        raw_contents = tf.read_file(result.rgbfile)
        #get RGB values out of the content
        result.rgb_image = tf.image.decode_jpeg(raw_contents)
        result.height = result.rgb_image.get_shape()[0]
        result.width = result.rgb_image.get_shape()[1]
    if data_type=='both' or data_type=='flow':
        raw_contents = tf.read_file(result.flowfile)
        result.flow_image = tf.image.decode_jpeg(raw_contents)
        result.height = result.flow_image.get_shape()[0]
        result.width = result.flow_image.get_shape()[1]
    result.data_type = data_type

    return result


def _generate_image_and_label_batch(image, label, min_queue_examples, batch_size):
    """Construct a queued batch of images and labels.
    Args:
        image: 3-D Tensor of [height, width, 3] of type.float32.
        label: 1-D Tensor of type.int32
        min_queue_examples: int32, minimum number of samples to retain
        in the queue that provides of batches of examples.
        batch_size: Number of images per batch.
    Returns:
        images: Images. 4D tensor of [batch_size, height, width, 3] size.
        labels: Labels. 1D tensor of [batch_size] size.
    """
    # Create a queue that shuffles the examples, and then
    # read 'batch_size' images + labels from the example queue.
    num_preprocess_threads = 8
    images, label_batch = tf.train.shuffle_batch(
        [image, label],
        batch_size=batch_size,
        num_threads=num_preprocess_threads,
        capacity=min_queue_examples + 3 * batch_size,
        min_after_dequeue=min_queue_examples)

    return images, tf.reshape(label_batch, [batch_size])

    
def distorted_inputs(data_list='imglist_generated_tmp.txt', batch_size=10, data_type='app'):
    """
    Args:
        data_list: Path to the data list file.
        batch_size: Number of images per batch.
        data_type: appearance, flow or both
    Returns:
        images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, IMAGE_DEPTH] size.
        labels: Labels. 1D tensor of [batch_size] size.
    """
    #removing label, obtaining list containing /path/to/image_x
    image_list_file = open(data_list, 'r')
    image_list = image_list_file.readlines()
    image_list = [line[:-1] for line in image_list]

    #output imagefilenames to a queue for an input pipeline
    input_queue = tf.train.string_input_producer(image_list, num_epochs=max_num_epochs, shuffle=True, name='read_input') 
    
    #get a line of the input_queue and return a decoded object with image-field and label-field
    result = read_my_file_format(input_queue.dequeue(), data_type)
    # Randomly crop a [height, width] section of the image.
    #==> ensure the size of the tensor needed by shuffle_batch
    #PIL Image.show cannot handle data type float32
    reshaped_image = tf.cast(result.rgb_image, tf.float32)
    #reshaped_image = tf.transpose(reshaped_image, [1, 2, 0])
    distorted_image = tf.random_crop(reshaped_image, [384, 512, 3])
    
    # randomize the order of the operations.
    distorted_image = tf.image.random_brightness(distorted_image,max_delta=63)
    distorted_image = tf.image.random_contrast(distorted_image,lower=0.2, upper=1.8)
    
    # Display the training images in the visualizer.
    tf.image_summary('image', distorted_image)

    # Subtract off the mean and divide by the variance of the pixels.
    whitened_image = tf.image.per_image_whitening(distorted_image)
    
    # Ensure that the random shuffling has good mixing properties.
    min_fraction_of_examples_in_queue = 0.4
    min_queue_examples = int(NUM_EXAMPLES_PER_EPOCH_FOR_TRAIN *
                            min_fraction_of_examples_in_queue)
    print ('Filling queue with %d images. '
         'This will take a few minutes.' % min_queue_examples)

    return _generate_image_and_label_batch(whitened_image, result.label, min_queue_examples, batch_size)

def image_preprocessing(image):
    """Decode and preprocess one image for evaluation or training.

    Args:
        image_buffer: JPEG encoded string Tensor
    Returns:
        3-D float Tensor containing an appropriately scaled image
    """
    #get a line of the input_queue and return a decoded object with image-field and label-field
    
    # After this point, all image pixels reside in [0,1)
    # until the very end, when they're rescaled to (-1, 1).  The various
    # adjust_* ops all require this range for dtype float.
    image = tf.image.convert_image_dtype(image, dtype=tf.float32)
    
    image = tf.image.central_crop(image, central_fraction=0.875)

    ## Resize the image to the original height and width.
    image = tf.expand_dims(image, 0)
    image = tf.image.resize_bilinear(image, [384, 512],
                                     align_corners=False)
    image = tf.squeeze(image, [0])
    
    # Finally, rescale to [-1,1] instead of [0, 1)
    image = tf.sub(image, 0.5)
    image = tf.mul(image, 2.0)
    
    image = tf.reshape(image, shape=[384,512,3])
    return image
    
def inputs(data_list='imglist_generated_tmp.txt', batch_size=32, data_type='app', num_preprocess_threads=None):
    """
    Args:
        data_list: Path to the data list file.
        batch_size: Number of images per batch.
        data_type: appearance, flow or both
    Returns:
        images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, IMAGE_DEPTH] size.
        labels: Labels. 1D tensor of [batch_size] size.
    """
    #removing label, obtaining list containing /path/to/image_x
    image_list_file = open(data_list, 'r')
    image_list = image_list_file.readlines()
    image_list = [line[:-1] for line in image_list]

    #output imagefilenames to a queue for an input pipeline
    input_queue = tf.train.string_input_producer(image_list, num_epochs=max_num_epochs, shuffle=False, name='read_input') 
        
    images_and_labels = []
    for thread_id in range(num_preprocess_threads):
        result = read_my_file_format(input_queue.dequeue(), data_type)
        image = image_preprocessing(result.rgb_image)
        images_and_labels.append([image, result.label])
        
    images, labels = tf.train.batch_join(images_and_labels,
        batch_size=batch_size,
        capacity=2*num_preprocess_threads*batch_size)
    
    images = tf.cast(images, tf.float32)
    images = tf.reshape(images, shape=[batch_size, 384, 512, 3])
    
    return images, labels
    

#####################################################################

if __name__ == '__main__':
    print "-----------------------------------"
    print "Local run of pilot_read for testing"
    print "-----------------------------------"
    
    with tf.Graph().as_default(), tf.Session() as sess:
        images, labels = inputs(num_preprocess_threads=4)
        image_sum = tf.image_summary('images', images)  
        
        #import pdb; pdb.set_trace()
        # Display the training images in the visualizer.
        location = '/esat/qayd/kkelchte/tensorflow/lstm_logs/image_test'
        summary_writer = tf.train.SummaryWriter(location, graph=sess.graph)
        
        #images, labels = distorted_inputs(image_label_list, batch_size, data_type)
        #PIL cannot vizualise float32 images, only uint8
        #Visualizing whitened images is useless because its all black...
        #var = tf.Variable(128, dtype=tf.uint8)
        #c_im = tf.cast(images, tf.uint8)
        #viz_im = tf.add(tf.mul(c_im, var), var)
        
        init_op = tf.initialize_all_variables()
        sess.run(init_op)
        
        # get coordinator for arranging the different threads
        coord = tf.train.Coordinator()
        # start all queue runners in the graph and returns a list of threads
        threads = tf.train.start_queue_runners(coord=coord)
        
        images, labels, summary = sess.run([images, labels, image_sum])
        #import pdb; pdb.set_trace()
        summary_writer.add_summary(summary)
        ##for i in range(1): #length of your filename list
        #    im_rgb = sess.run(viz_im)
        #    print type(im_rgb)
        #    print str(im_rgb.shape)
        #    Image.fromarray(np.asarray(im_rgb[0])).show()
        #import pdb; pdb.set_trace()
        #Image.fromarray(np.asarray(im_rgb[0])).show()
        #Image.fromarray(np.asarray(im_flow)).show()
        
        #coordinator asks all threads to stop
        coord.request_stop()
        #wait till all threads are stopped
        coord.join(threads)
