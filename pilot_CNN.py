import pilot_data
import os
import tensorflow as tf
from os import listdir
from os.path import isfile,join
import numpy as np
from PIL import Image
import string

#number of times data is used for training and given as input
max_num_epochs = 5
#file generated by create_image_list.py
image_label_list = 'imglist_generated_tmp.txt'
batch_size = 10
data_type = 'both' #can be app, flow or both

class DataError(Exception):
    def __init__(self, value):
        self.value = value
    def __str__(self):
        return repr(self.value)

### DEFINE CNN NETWORK ###

#def inference():

#def loss():

#def training():

### READ IN DATA    ###
def read_my_file_format(filename_and_label_tensor, data_type='app'):
    """Consumes a single filename and label as a ' '-delimited string.

    Args:
        filename_and_label_tensor: A scalar string tensor.

    Returns:
        An object representing a single data object with the following fields:
        height: number of rows in the result
        width: number of columns in the result
        depth: number of color channels in the result 3 for 1 image
        label: an int32 Tensor with the label in the range 0..3.
        rgb_image: a [height, width, depth] uint8 Tensor with the image data 
        flow_image: a [height, width, depth] uint8 Tensor with the image data
    """
    class DataRecord(object):
        pass
    result = DataRecord()
    #get filename and label from the scalar string tensor
    result.rgbfile, result.flowfile, result.label = tf.decode_csv(filename_and_label_tensor, [[""], [""], [""]], " ")
    if data_type=='both' or data_type=='app':
        #read_file to get a string representation of the image in filename
        raw_contents = tf.read_file(result.rgbfile)
        #get RGB values out of the content
        result.rgb_image = tf.image.decode_jpeg(raw_contents)
        result.height = result.rgb_image.get_shape()[0]
        result.width = result.rgb_image.get_shape()[1]
    if data_type=='both' or data_type=='flow':
        raw_contents = tf.read_file(result.flowfile)
        result.flow_image = tf.image.decode_jpeg(raw_contents)
        result.height = result.flow_image.get_shape()[0]
        result.width = result.flow_image.get_shape()[1]
    result.data_type = data_type
    return result

def distorted_inputs(data_list, batch_size, data_type='app'):
    """
    Args:
        data_dir: Path to the data list file.
        batch_size: Number of images per batch.
    Returns:
        images: Images. 4D tensor of [batch_size, IMAGE_SIZE, IMAGE_SIZE, 3] size.
        labels: Labels. 1D tensor of [batch_size] size.
    """
    #removing label, obtaining list containing /path/to/image_x
    image_list_file = open(data_list, 'r')
    image_list = image_list_file.readlines()
    image_list = [line[:-1] for line in image_list]

    #output imagefilenames to a queue for an input pipeline
    input_queue = tf.train.string_input_producer(image_list, num_epochs=max_num_epochs, shuffle=True, name='read_input') 
    
    #get a line of the input_queue and return a decoded object with image-field and label-field
    result = read_my_file_format(input_queue.dequeue(), data_type)
    distorted_image = result.rgb_image
    # randomize the order their operation.
    distorted_image = tf.image.random_brightness(distorted_image,max_delta=63)
    distorted_image = tf.image.random_contrast(distorted_image,                                       lower=0.2, upper=1.8)

    # Subtract off the mean and divide by the variance of the pixels.
    distorted_image = tf.image.per_image_whitening(distorted_image)

  
    return result


### SCRIPT ###
result = distorted_inputs(image_label_list, batch_size, data_type)

init_op = tf.initialize_all_variables()
with tf.Session() as sess:
    sess.run(init_op)
    #sess.as_default()
    # get coordinator for arranging the different threads
    coord = tf.train.Coordinator()
    # start all queue runners in the graph and returns a list of threads
    threads = tf.train.start_queue_runners(coord=coord)
    print "number of threads ",len(threads)
    
    #im = sess.run(result.flow_image)
    #Image.fromarray(np.asarray(im)).show()
    for i in range(3): #length of your filename list
        im_rgb, im_flow, lbl = sess.run([result.rgb_image, result.flow_image, result.label])
        #import pdb; pdb.set_trace()
        Image.fromarray(np.asarray(im_rgb)).show()
        Image.fromarray(np.asarray(im_flow)).show()
    #Image._show(Image.fromarray(np.asarray(im)), title="MYIMAGE")

    #coordinator asks all threads to stop
    coord.request_stop()
    #wait till all threads are stopped
    coord.join(threads)
